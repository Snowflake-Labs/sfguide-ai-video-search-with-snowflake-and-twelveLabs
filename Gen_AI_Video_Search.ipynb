{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ab3d0d-8bca-422e-ace6-ae19aded5148",
   "metadata": {
    "collapsed": false,
    "name": "Overview",
    "resultHeight": 857
   },
   "source": [
    "# AI Video Search with Snowflake and TwelveLabs\n",
    "### Multimodal Videos Processing App using Twelvelabs, Whisper, and Snowflake Cortex\n",
    "\n",
    "For prerequisites and setup instructions, check out the [README](https://github.com/Snowflake-Labs/sfguide-ai-video-search-with-snowflake-and-twelveLabs/blob/main/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Install_Libraries",
    "resultHeight": 26334
   },
   "outputs": [],
   "source": [
    "!pip install twelvelabs\n",
    "!pip install git+https://github.com/openai/whisper.git ffmpeg-python moviepy\n",
    "# !apt install ffmpeg -y\n",
    "!DEBIAN_FRONTEND=noninteractive apt-get install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392068cc-ac1d-4aea-b511-a37eb563534c",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Import_Libraries",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.models.embed import EmbeddingsTask\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from twelvelabs.models.task import Task\n",
    "import requests\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import snowflake\n",
    "from snowflake import cortex\n",
    "\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca098690-2084-4686-9a83-454fae87cac7",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "Videos_List",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "video_urls = ['https://sfquickstarts.s3.us-west-1.amazonaws.com/misc/videos/snowflake_build2024_announcements.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31310039-efa6-4b59-abd0-1eb1d28d64fb",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "UDTF_Generate_Video_Embeddings",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import udtf, lit, Tuple\n",
    "from snowflake.snowpark.types import FloatType, StringType, StructType, StructField, Iterable, VectorType\n",
    "\n",
    "session.clear_imports()\n",
    "session.add_import('@\"DASH_DB\".\"DASH_SCHEMA\".\"DASH_PKGS\"/twelvelabs.zip')\n",
    "@udtf(name=\"create_video_embeddings\",\n",
    "     packages=['httpx','pydantic'],\n",
    "     external_access_integrations=['twelvelabs_access_integration'],\n",
    "     secrets={'cred': 'twelve_labs_api'},\n",
    "     if_not_exists=True,\n",
    "     is_permanent=True,\n",
    "     stage_location='@DASH_DB.DASH_SCHEMA.DASH_UDFS',\n",
    "     output_schema=StructType([\n",
    "        StructField(\"embedding\", VectorType(float,1024)),\n",
    "        StructField(\"start_offset_sec\", FloatType()),\n",
    "        StructField(\"end_offset_sec\", FloatType()),\n",
    "        StructField(\"embedding_scope\", StringType())\n",
    "    ])\n",
    "    )\n",
    "class create_video_embeddings:\n",
    "    def __init__(self):\n",
    "        from twelvelabs import TwelveLabs\n",
    "        from twelvelabs.models.embed import EmbeddingsTask\n",
    "        import _snowflake\n",
    "        \n",
    "        twelve_labs_api_key = _snowflake.get_generic_secret_string('cred') \n",
    "        twelvelabs_client = TwelveLabs(api_key=twelve_labs_api_key)\n",
    "        self.twelvelabs_client = twelvelabs_client\n",
    "\n",
    "    def process(self, video_url: str) -> Iterable[Tuple[list, float, float, str]]:\n",
    "        # Create an embeddings task\n",
    "        task = self.twelvelabs_client.embed.task.create(\n",
    "            model_name=\"Marengo-retrieval-2.7\",\n",
    "            video_url=video_url\n",
    "        )\n",
    "        \n",
    "        # Wait for the task to complete\n",
    "        status = task.wait_for_done(sleep_interval=60)\n",
    "\n",
    "        # Retrieve and process embeddings\n",
    "        task = task.retrieve()\n",
    "        if task.video_embedding is not None and task.video_embedding.segments is not None:\n",
    "            for segment in task.video_embedding.segments:\n",
    "                yield (\n",
    "                    segment.embeddings_float,  # Embedding (list of floats)\n",
    "                    segment.start_offset_sec,  # Start offset in seconds\n",
    "                    segment.end_offset_sec,    # End offset in seconds\n",
    "                    segment.embedding_scope,   # Embedding scope\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72585787-a622-4d90-90ea-5d92f53e768b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "Save_Video_Embeddings",
    "resultHeight": 438
   },
   "outputs": [],
   "source": [
    "df = session.create_dataframe(video_urls,schema=['url'])\n",
    "df = df.join_table_function(create_video_embeddings(df['url']).over(partition_by=\"url\"))\n",
    "df.write.mode('overwrite').save_as_table('video_embeddings')\n",
    "df = session.table('video_embeddings')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536408a7-fde9-45f8-ba86-b44ace446178",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "PyFn_Transcribe_Videos",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from moviepy import VideoFileClip\n",
    "import whisper\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress Whisper warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Set MoviePy logger level to ERROR or CRITICAL to suppress INFO logs\n",
    "logging.getLogger(\"moviepy\").setLevel(logging.ERROR)\n",
    "\n",
    "# Load the Whisper model once\n",
    "whisper_model = whisper.load_model(\"base\")  # or any other model you want to use, e.g., 'small', 'medium', 'large'\n",
    "\n",
    "def download_video_from_s3(video_url, output_video_path, status):\n",
    "    try:\n",
    "        # status.caption(\"Downloading video file from S3...\")\n",
    "        urllib.request.urlretrieve(video_url, output_video_path)\n",
    "        # status.caption(f\"Video downloaded to {output_video_path}.\")\n",
    "        return output_video_path\n",
    "    except Exception as e:\n",
    "        status.caption(f\"An error occurred during video download: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_audio_from_video(video_path, output_audio_path, status, start_time=None, end_time=None):\n",
    "    try:\n",
    "        # status.caption(\"Extracting audio from video...\")\n",
    "        video_clip = VideoFileClip(video_path)\n",
    "        \n",
    "        # If start and end times are provided, trim the video\n",
    "        if start_time is not None or end_time is not None:\n",
    "            video_clip = video_clip.subclipped(start_time, end_time)\n",
    "        \n",
    "        video_clip.audio.write_audiofile(output_audio_path)\n",
    "        # status.caption(f\"Audio extracted to {output_audio_path}.\")\n",
    "        return output_audio_path\n",
    "    except Exception as e:\n",
    "        status.caption(f\"An error occurred during audio extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_with_whisper(audio_path, status):\n",
    "    try:\n",
    "        # status.caption(\"Transcribing audio with Whisper...\")\n",
    "        result = whisper_model.transcribe(audio_path)\n",
    "        # status.caption(\"Transcription complete.\")\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        status.caption(f\"An error occurred during transcription: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_video(video_url, status, temp_video_path=\"temp_video.mp4\", temp_audio_path=\"temp_audio.mp3\"):\n",
    "    try:\n",
    "        # Step 1: Download video from S3\n",
    "        video_path = download_video_from_s3(video_url, temp_video_path, status)\n",
    "        if not video_path:\n",
    "            return None\n",
    "\n",
    "        # Step 2: Extract audio from video\n",
    "        audio_path = extract_audio_from_video(video_path, temp_audio_path, status)\n",
    "        if not audio_path:\n",
    "            return None\n",
    "\n",
    "        # Step 3: Transcribe audio with Whisper\n",
    "        transcription = transcribe_with_whisper(audio_path, status)\n",
    "        return transcription\n",
    "    finally:\n",
    "        # Clean up temporary files\n",
    "        if os.path.exists(temp_video_path):\n",
    "            os.remove(temp_video_path)\n",
    "            # status.caption(\"Temporary video file removed.\")\n",
    "        if os.path.exists(temp_audio_path):\n",
    "            os.remove(temp_audio_path)\n",
    "            # status.caption(\"Temporary audio file removed.\")\n",
    "\n",
    "def transcribe_video_clip(video_url, status, start_time, end_time, temp_video_path=\"temp_video.mp4\", temp_audio_path=\"temp_audio_clip.mp3\"):\n",
    "    try:\n",
    "        # Step 1: Download video from S3\n",
    "        video_path = download_video_from_s3(video_url, temp_video_path, status)\n",
    "        if not video_path:\n",
    "            return None\n",
    "\n",
    "        # Step 2: Extract audio from the specified clip\n",
    "        audio_path = extract_audio_from_video(video_path, temp_audio_path, status, start_time, end_time)\n",
    "        if not audio_path:\n",
    "            return None\n",
    "\n",
    "        # Step 3: Transcribe the extracted audio clip with Whisper\n",
    "        transcription = transcribe_with_whisper(audio_path, status)\n",
    "        return transcription\n",
    "    finally:\n",
    "        # Clean up temporary files\n",
    "        if os.path.exists(temp_video_path):\n",
    "            os.remove(temp_video_path)\n",
    "            # status.caption(\"Temporary video file removed.\")\n",
    "        if os.path.exists(temp_audio_path):\n",
    "            os.remove(temp_audio_path)\n",
    "            # status.caption(\"Temporary audio file removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73487b72-beb7-4542-b29b-e0b3fd51a1ff",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "PyFn_Similarity_Scores",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# TODO: Replace tlk_XXXXXXXXXXXXXXXXXX with your Twelve Labs API Key\n",
    "TWELVE_LABS_API_KEY =\"tlk_XXXXXXXXXXXXXXXXXX\"\n",
    "# Initialize the Twelve Labs client\n",
    "twelvelabs_client = TwelveLabs(api_key=TWELVE_LABS_API_KEY)\n",
    "\n",
    "def truncate_text(text, max_tokens=77):\n",
    "    # Truncate text to roughly 77 tokens (assuming ~6 chars per token on average)\n",
    "    return text[:max_tokens * 6]  # Adjust based on actual tokenization behavior\n",
    "\n",
    "def similarity_scores(search_text,results_limit=5):\n",
    "    # Twelve Labs Embed API supports text-to-embedding  \n",
    "    truncated_text = truncate_text(search_text, max_tokens=77)\n",
    "    \n",
    "    twelvelabs_response = twelvelabs_client.embed.create(\n",
    "      model_name=\"Marengo-retrieval-2.7\",\n",
    "      text=truncated_text,\n",
    "      text_truncate='start'\n",
    "    )\n",
    "\n",
    "    if twelvelabs_response.text_embedding is not None and twelvelabs_response.text_embedding.segments is not None:\n",
    "        text_query_embeddings = twelvelabs_response.text_embedding.segments[0].embeddings_float\n",
    "        return session.sql(f\"\"\"\n",
    "            SELECT URL as VIDEO_URL,START_OFFSET_SEC,END_OFFSET_SEC,\n",
    "            round(VECTOR_COSINE_SIMILARITY(embedding::VECTOR(FLOAT, 1024),{text_query_embeddings}::VECTOR(FLOAT, 1024)),2) as SIMILARITY_SCORE \n",
    "            from video_embeddings order by similarity_score desc limit {results_limit}\"\"\")\n",
    "    else:\n",
    "        return twelvelabs_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac865adc-733a-4f26-9234-06ac336a1f9d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "Search_Clips_Application",
    "resultHeight": 760
   },
   "outputs": [],
   "source": [
    "st.subheader(\"Search Clips Application\")\n",
    "\n",
    "with st.container():\n",
    "    with st.expander(\"Enter search text and select max results\", expanded=True):\n",
    "        left_col,mid_col,right_col = st.columns(3)\n",
    "        with left_col:\n",
    "            entered_text = st.text_input('Search Text')\n",
    "        with mid_col:\n",
    "            max_results = st.selectbox('Max Results',(1,2,3,4,5))\n",
    "        with right_col:\n",
    "            selected_llm = st.selectbox('Select Summary LLM',('llama3.2-3b','llama3.1-405b','mistral-large2', 'snowflake-arctic',))\n",
    "        \n",
    "with st.container():\n",
    "    _,mid_col1,_ = st.columns([.3,.4,.2])\n",
    "    with mid_col1:\n",
    "        similarity_scores_btn = st.button('Search and Summarize Matching Video Clips',type=\"primary\")\n",
    "\n",
    "with st.container():\n",
    "    if similarity_scores_btn:\n",
    "        if entered_text:\n",
    "            with st.status(\"In progress...\") as status:\n",
    "                df = similarity_scores(entered_text,max_results).to_pandas()\n",
    "                status.subheader(f\"Top {max_results} clip(s) for search query '{entered_text}'\")\n",
    "                for row in df.itertuples():\n",
    "                    transcribed_clip = transcribe_video_clip(row.VIDEO_URL, status, row.START_OFFSET_SEC, row.END_OFFSET_SEC)\n",
    "                    prompt = f\"\"\"\n",
    "                    [INST] Summarize the following and include name of the video as well as start and end clip times in seconds with everything in natural language as opposed to attributes: \n",
    "                    ###\n",
    "                    Video URL: {row.VIDEO_URL},\n",
    "                    Clip Start: {row.START_OFFSET_SEC} | Clip End: {row.END_OFFSET_SEC} | Similarity Score: {row.SIMILARITY_SCORE}\n",
    "                    Clip Transcript: {transcribed_clip}\n",
    "                    ###\n",
    "                    [/INST]\n",
    "                    \"\"\"\n",
    "                    status.write(f\"Video URL: {row.VIDEO_URL}\")\n",
    "                    status.caption(f\"-- Clip Start: {row.START_OFFSET_SEC} | Clip End: {row.END_OFFSET_SEC} | Similarity Score: {row.SIMILARITY_SCORE}\")\n",
    "                    status.caption(f\"-- Clip Transcript: {transcribed_clip}\")\n",
    "                    status.write(f\"Summary: {cortex.Complete(selected_llm,prompt)}\")\n",
    "                    status.divider()\n",
    "                status.update(label=\"Done!\", state=\"complete\", expanded=True)\n",
    "        else:\n",
    "            st.caption(\"User ERROR: Please enter search text!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
